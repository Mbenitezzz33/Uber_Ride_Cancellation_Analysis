{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af67eba-4752-4859-a76a-638744922bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Date/Time handling (for cyclical time features)\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualization for sanity checks (optional but useful)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modeling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "# Suppress warnings to reduce clutter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "698f5e1e-3e14-4d15-8c3b-4c17b94c2df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Booking ID</th>\n",
       "      <th>Booking Status</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Vehicle Type</th>\n",
       "      <th>Pickup Location</th>\n",
       "      <th>Drop Location</th>\n",
       "      <th>Waiting Time</th>\n",
       "      <th>Ride Duration</th>\n",
       "      <th>...</th>\n",
       "      <th>Reason for cancelling by Customer</th>\n",
       "      <th>Cancelled Rides by Driver</th>\n",
       "      <th>Driver Cancellation Reason</th>\n",
       "      <th>Incomplete Rides</th>\n",
       "      <th>Incomplete Rides Reason</th>\n",
       "      <th>Booking Value</th>\n",
       "      <th>Ride Distance</th>\n",
       "      <th>Driver Ratings</th>\n",
       "      <th>Customer Rating</th>\n",
       "      <th>Payment Method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/23/2024</td>\n",
       "      <td>12:29:38</td>\n",
       "      <td>\"CNR5884300\"</td>\n",
       "      <td>No Driver Found</td>\n",
       "      <td>\"CID1982111\"</td>\n",
       "      <td>eBike</td>\n",
       "      <td>Palam Vihar</td>\n",
       "      <td>Jhilmil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/29/2024</td>\n",
       "      <td>18:01:39</td>\n",
       "      <td>\"CNR1326809\"</td>\n",
       "      <td>Incomplete</td>\n",
       "      <td>\"CID4604802\"</td>\n",
       "      <td>Go Sedan</td>\n",
       "      <td>Shastri Nagar</td>\n",
       "      <td>Gurgaon Sector 56</td>\n",
       "      <td>4.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Vehicle Breakdown</td>\n",
       "      <td>237.0</td>\n",
       "      <td>5.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/23/2024</td>\n",
       "      <td>8:56:10</td>\n",
       "      <td>\"CNR8494506\"</td>\n",
       "      <td>Completed</td>\n",
       "      <td>\"CID9202816\"</td>\n",
       "      <td>Auto</td>\n",
       "      <td>Khandsa</td>\n",
       "      <td>Malviya Nagar</td>\n",
       "      <td>13.4</td>\n",
       "      <td>25.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>627.0</td>\n",
       "      <td>13.58</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Debit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/21/2024</td>\n",
       "      <td>17:17:25</td>\n",
       "      <td>\"CNR8906825\"</td>\n",
       "      <td>Completed</td>\n",
       "      <td>\"CID2610914\"</td>\n",
       "      <td>Premier Sedan</td>\n",
       "      <td>Central Secretariat</td>\n",
       "      <td>Inderlok</td>\n",
       "      <td>13.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416.0</td>\n",
       "      <td>34.02</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>UPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/16/2024</td>\n",
       "      <td>22:08:00</td>\n",
       "      <td>\"CNR1950162\"</td>\n",
       "      <td>Completed</td>\n",
       "      <td>\"CID9933542\"</td>\n",
       "      <td>Bike</td>\n",
       "      <td>Ghitorni Village</td>\n",
       "      <td>Khan Market</td>\n",
       "      <td>5.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>737.0</td>\n",
       "      <td>48.21</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>UPI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time    Booking ID   Booking Status   Customer ID  \\\n",
       "0   3/23/2024  12:29:38  \"CNR5884300\"  No Driver Found  \"CID1982111\"   \n",
       "1  11/29/2024  18:01:39  \"CNR1326809\"       Incomplete  \"CID4604802\"   \n",
       "2   8/23/2024   8:56:10  \"CNR8494506\"        Completed  \"CID9202816\"   \n",
       "3  10/21/2024  17:17:25  \"CNR8906825\"        Completed  \"CID2610914\"   \n",
       "4   9/16/2024  22:08:00  \"CNR1950162\"        Completed  \"CID9933542\"   \n",
       "\n",
       "    Vehicle Type      Pickup Location      Drop Location  Waiting Time  \\\n",
       "0          eBike          Palam Vihar            Jhilmil           NaN   \n",
       "1       Go Sedan        Shastri Nagar  Gurgaon Sector 56           4.9   \n",
       "2           Auto              Khandsa      Malviya Nagar          13.4   \n",
       "3  Premier Sedan  Central Secretariat           Inderlok          13.1   \n",
       "4           Bike     Ghitorni Village        Khan Market           5.3   \n",
       "\n",
       "   Ride Duration  ...  Reason for cancelling by Customer  \\\n",
       "0            NaN  ...                                NaN   \n",
       "1           14.0  ...                                NaN   \n",
       "2           25.8  ...                                NaN   \n",
       "3           28.5  ...                                NaN   \n",
       "4           19.6  ...                                NaN   \n",
       "\n",
       "  Cancelled Rides by Driver  Driver Cancellation Reason Incomplete Rides  \\\n",
       "0                       NaN                         NaN              NaN   \n",
       "1                       NaN                         NaN              1.0   \n",
       "2                       NaN                         NaN              NaN   \n",
       "3                       NaN                         NaN              NaN   \n",
       "4                       NaN                         NaN              NaN   \n",
       "\n",
       "   Incomplete Rides Reason Booking Value  Ride Distance  Driver Ratings  \\\n",
       "0                      NaN           NaN            NaN             NaN   \n",
       "1        Vehicle Breakdown         237.0           5.73             NaN   \n",
       "2                      NaN         627.0          13.58             4.9   \n",
       "3                      NaN         416.0          34.02             4.6   \n",
       "4                      NaN         737.0          48.21             4.1   \n",
       "\n",
       "   Customer Rating  Payment Method  \n",
       "0              NaN             NaN  \n",
       "1              NaN             UPI  \n",
       "2              4.9      Debit Card  \n",
       "3              5.0             UPI  \n",
       "4              4.3             UPI  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"Benitez_Matthias_Uber_Dashboard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0913a06f-0838-49c0-9cc7-8d04f1931e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147580 entries, 0 to 147579\n",
      "Data columns (total 21 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   Date                               147580 non-null  object \n",
      " 1   Time                               147580 non-null  object \n",
      " 2   Booking ID                         147580 non-null  object \n",
      " 3   Booking Status                     147580 non-null  object \n",
      " 4   Customer ID                        147580 non-null  object \n",
      " 5   Vehicle Type                       147580 non-null  object \n",
      " 6   Pickup Location                    147580 non-null  object \n",
      " 7   Drop Location                      147580 non-null  object \n",
      " 8   Waiting Time                       137263 non-null  float64\n",
      " 9   Ride Duration                      100372 non-null  float64\n",
      " 10  Cancelled Rides by Customer        10324 non-null   float64\n",
      " 11  Reason for cancelling by Customer  10324 non-null   object \n",
      " 12  Cancelled Rides by Driver          26567 non-null   float64\n",
      " 13  Driver Cancellation Reason         26567 non-null   object \n",
      " 14  Incomplete Rides                   8855 non-null    float64\n",
      " 15  Incomplete Rides Reason            8855 non-null    object \n",
      " 16  Booking Value                      100372 non-null  float64\n",
      " 17  Ride Distance                      100372 non-null  float64\n",
      " 18  Driver Ratings                     91517 non-null   float64\n",
      " 19  Customer Rating                    91517 non-null   float64\n",
      " 20  Payment Method                     100372 non-null  object \n",
      "dtypes: float64(9), object(12)\n",
      "memory usage: 23.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e01d647f-df04-44d4-b1e1-ee191364fe72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== POTENTIAL LEAKAGE CANDIDATES (review) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>dtype</th>\n",
       "      <th>nonnull_completed</th>\n",
       "      <th>nonnull_canceled</th>\n",
       "      <th>completed_minus_canceled</th>\n",
       "      <th>known_post_ride</th>\n",
       "      <th>heuristic_leakage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ride Duration</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ride Distance</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Payment Method</td>\n",
       "      <td>object</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Booking Value</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Driver Ratings</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.827</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Customer Rating</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.827</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature    dtype  nonnull_completed  nonnull_canceled  \\\n",
       "4    Ride Duration  float64              0.907               0.0   \n",
       "6    Ride Distance  float64              0.907               0.0   \n",
       "9   Payment Method   object              0.907               0.0   \n",
       "5    Booking Value  float64              0.907               0.0   \n",
       "7   Driver Ratings  float64              0.827               0.0   \n",
       "8  Customer Rating  float64              0.827               0.0   \n",
       "\n",
       "   completed_minus_canceled  known_post_ride  heuristic_leakage  \n",
       "4                     0.907             True               True  \n",
       "6                     0.907             True               True  \n",
       "9                     0.907            False               True  \n",
       "5                     0.907             True               True  \n",
       "7                     0.827             True               True  \n",
       "8                     0.827             True               True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAFE TO USE (observable before accept/complete) ===\n",
      "['Drop Location', 'Pickup Location', 'Vehicle Type', 'Rider_Total_Rides', 'Hour', 'Weekday', 'Canceled', 'hour_sin', 'Rider_Cancel_Rate', 'Driver_Total_Rides', 'Driver_Cancel_Rate', 'wday_sin', 'hour_cos', 'wday_cos', 'Waiting Time']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1) Define target (0=Completed, 1=Cancelled) robustly ---\n",
    "TARGET_COL = \"_CancelledFlag\"\n",
    "if TARGET_COL not in df.columns:\n",
    "    if \"Booking Status\" in df.columns:\n",
    "        df[TARGET_COL] = df[\"Booking Status\"].astype(str).str.lower().str.contains(\"cancel\").astype(int)\n",
    "    elif \"Cancelled\" in df.columns:\n",
    "        df[TARGET_COL] = df[\"Cancelled\"].astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"Can't find a cancellation label. Add one or ensure 'Booking Status' exists.\")\n",
    "\n",
    "# --- 2) Columns to evaluate (skip ids/time stamps you won't model directly) ---\n",
    "skip_cols = {\n",
    "    TARGET_COL, \"Booking Status\", \"Booking ID\", \"Customer ID\", \"Driver ID\",\n",
    "    \"Date\", \"Time\", \"Request_Datetime\"\n",
    "}\n",
    "cols_to_check = [c for c in df.columns if c not in skip_cols]\n",
    "\n",
    "# --- 3) Known post-ride / leakage features (business rules) ---\n",
    "known_post_ride = {\n",
    "    \"Ride Duration\", \"Ride Distance\", \"Booking Value\",\n",
    "    \"Driver Ratings\", \"Customer Rating\",\n",
    "    \"Incomplete Rides\", \"Incomplete Rides Reason\",\n",
    "    \"Reason for cancelling by Customer\", \"Driver Cancellation Reason\",\n",
    "    \"Cancelled Rides by Customer\", \"Cancelled Rides by Driver\"\n",
    "}\n",
    "# NOTE: If you later engineer \"driver/rider total rides/cancel rate\",\n",
    "#       treat them as leakage unless computed from ONLY prior history (time-aware).\n",
    "\n",
    "# --- 4) Compute non-null rates per class for EACH column (works for any dtype) ---\n",
    "rows = []\n",
    "for col in cols_to_check:\n",
    "    compl_rate = df.loc[df[TARGET_COL] == 0, col].notna().mean()  # completed\n",
    "    canc_rate  = df.loc[df[TARGET_COL] == 1, col].notna().mean()  # cancelled\n",
    "    overall    = df[col].notna().mean()\n",
    "    diff       = compl_rate - canc_rate  # +ve => appears mostly when completed\n",
    "    rows.append({\n",
    "        \"feature\": col,\n",
    "        \"dtype\": str(df[col].dtype),\n",
    "        \"nonnull_overall\": round(overall, 3),\n",
    "        \"nonnull_completed\": round(compl_rate, 3),\n",
    "        \"nonnull_canceled\": round(canc_rate, 3),\n",
    "        \"completed_minus_canceled\": round(diff, 3),\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(rows).sort_values(\"completed_minus_canceled\", ascending=False)\n",
    "\n",
    "# --- 5) Heuristic leakage flag: big presence only after completion ---\n",
    "THRESH = 0.30  # tweak if you want stricter/looser\n",
    "summary[\"heuristic_leakage\"] = summary[\"completed_minus_canceled\"] > THRESH\n",
    "summary[\"known_post_ride\"]   = summary[\"feature\"].isin(known_post_ride)\n",
    "summary[\"leakage_flag\"]      = summary[\"heuristic_leakage\"] | summary[\"known_post_ride\"]\n",
    "\n",
    "# --- 6) Final allowlist for modeling (observable at request time) ---\n",
    "safe_features = summary.loc[~summary[\"leakage_flag\"], \"feature\"].tolist()\n",
    "\n",
    "print(\"=== POTENTIAL LEAKAGE CANDIDATES (review) ===\")\n",
    "display(summary.loc[summary[\"leakage_flag\"]]\n",
    "        [[\"feature\",\"dtype\",\"nonnull_completed\",\"nonnull_canceled\",\"completed_minus_canceled\",\"known_post_ride\",\"heuristic_leakage\"]]\n",
    "        .head(30))\n",
    "\n",
    "print(\"\\n=== SAFE TO USE (observable before accept/complete) ===\")\n",
    "print(safe_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e7b5e46-4c33-4423-831c-7c49a0c23491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Hour Count: 0\n",
      "Null Weekday Count: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert Date and Time columns\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce')\n",
    "\n",
    "# Combine into a single datetime\n",
    "df['Request_Datetime'] = df['Date'] + pd.to_timedelta(df['Time'].dt.time.astype(str))\n",
    "\n",
    "# Extract clean hour & weekday\n",
    "df['Hour'] = df['Request_Datetime'].dt.hour\n",
    "df['Weekday'] = df['Request_Datetime'].dt.weekday\n",
    "\n",
    "print(\"Null Hour Count:\", df['Hour'].isna().sum())\n",
    "print(\"Null Weekday Count:\", df['Weekday'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08646878-6d11-4163-be4a-43d05470d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19211  2927]\n",
      " [ 3763  3615]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.836     0.868     0.852     22138\n",
      "           1      0.553     0.490     0.519      7378\n",
      "\n",
      "    accuracy                          0.773     29516\n",
      "   macro avg      0.694     0.679     0.686     29516\n",
      "weighted avg      0.765     0.773     0.769     29516\n",
      "\n",
      "\n",
      "Top features (safe, pre-ride):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Payment Method_UPI</td>\n",
       "      <td>0.177484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waiting Time</td>\n",
       "      <td>0.174050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Payment Method_Cash</td>\n",
       "      <td>0.067960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hour_cos</td>\n",
       "      <td>0.033053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hour_sin</td>\n",
       "      <td>0.032432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Payment Method_Uber Wallet</td>\n",
       "      <td>0.029346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Payment Method_Credit Card</td>\n",
       "      <td>0.024491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wday_sin</td>\n",
       "      <td>0.021486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Payment Method_Debit Card</td>\n",
       "      <td>0.019856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wday_cos</td>\n",
       "      <td>0.014562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vehicle Type_Auto</td>\n",
       "      <td>0.008225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vehicle Type_Go Mini</td>\n",
       "      <td>0.007730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Vehicle Type_Go Sedan</td>\n",
       "      <td>0.007233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vehicle Type_Bike</td>\n",
       "      <td>0.006880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vehicle Type_Premier Sedan</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vehicle Type_eBike</td>\n",
       "      <td>0.004665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vehicle Type_Uber XL</td>\n",
       "      <td>0.002780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pickup Location_Gurgaon Railway Station</td>\n",
       "      <td>0.001234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Drop Location_Paharganj</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Drop Location_Kalkaji</td>\n",
       "      <td>0.001193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    feature  importance\n",
       "0                        Payment Method_UPI    0.177484\n",
       "1                              Waiting Time    0.174050\n",
       "2                       Payment Method_Cash    0.067960\n",
       "3                                  hour_cos    0.033053\n",
       "4                                  hour_sin    0.032432\n",
       "5                Payment Method_Uber Wallet    0.029346\n",
       "6                Payment Method_Credit Card    0.024491\n",
       "7                                  wday_sin    0.021486\n",
       "8                 Payment Method_Debit Card    0.019856\n",
       "9                                  wday_cos    0.014562\n",
       "10                        Vehicle Type_Auto    0.008225\n",
       "11                     Vehicle Type_Go Mini    0.007730\n",
       "12                    Vehicle Type_Go Sedan    0.007233\n",
       "13                        Vehicle Type_Bike    0.006880\n",
       "14               Vehicle Type_Premier Sedan    0.006154\n",
       "15                       Vehicle Type_eBike    0.004665\n",
       "16                     Vehicle Type_Uber XL    0.002780\n",
       "17  Pickup Location_Gurgaon Railway Station    0.001234\n",
       "18                  Drop Location_Paharganj    0.001211\n",
       "19                    Drop Location_Kalkaji    0.001193"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 1) Cyclical time encodings (safe: computed from Hour/Weekday) ===\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# make sure Hour/Weekday exist (you already created them)\n",
    "assert 'Hour' in df.columns and 'Weekday' in df.columns, \"Run the Hour/Weekday cell first.\"\n",
    "\n",
    "df['hour_sin'] = np.sin(2*np.pi*df['Hour']/24)\n",
    "df['hour_cos'] = np.cos(2*np.pi*df['Hour']/24)\n",
    "df['wday_sin'] = np.sin(2*np.pi*df['Weekday']/7)\n",
    "df['wday_cos'] = np.cos(2*np.pi*df['Weekday']/7)\n",
    "\n",
    "# === 2) Target: 1 = Canceled, 0 = Completed ===\n",
    "# (adjust the condition if your 'Booking Status' spellings differ)\n",
    "y = df['Booking Status'].str.lower().str.contains('cancel').astype(int)\n",
    "\n",
    "# === 3) SAFE (pre-ride) feature set ===\n",
    "# Keep only things known BEFORE acceptance/completion.\n",
    "candidate_safe = [\n",
    "    'Pickup Location', 'Drop Location', 'Vehicle Type', 'Payment Method',\n",
    "    'Waiting Time',              # queue/ETA at request time (safe)\n",
    "    'hour_sin','hour_cos','wday_sin','wday_cos'\n",
    "    # NOTE: deliberately EXCLUDED: Ride Duration, Ride Distance, Booking Value,\n",
    "    # Driver Ratings, Customer Rating, and any totals/cancel rates by rider/driver\n",
    "    # unless you’ve precomputed them from strictly *prior* history.\n",
    "]\n",
    "\n",
    "# Use only columns that actually exist to avoid key errors on fresh machines\n",
    "safe_features = [c for c in candidate_safe if c in df.columns]\n",
    "X = df[safe_features].copy()\n",
    "\n",
    "# === 4) Preprocess & Model ===\n",
    "num_features = [c for c in ['Waiting Time','hour_sin','hour_cos','wday_sin','wday_cos'] if c in X.columns]\n",
    "cat_features = [c for c in ['Pickup Location','Drop Location','Vehicle Type','Payment Method'] if c in X.columns]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('impute', SimpleImputer(strategy='median'))\n",
    "        ]), num_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "            ('enc', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), cat_features),\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        class_weight='balanced_subsample',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# === 5) Train / Test split & fit ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# === 6) Evaluate ===\n",
    "pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print()\n",
    "print(classification_report(y_test, pred, digits=3))\n",
    "\n",
    "# === 7) Feature importances (grouped back to human-readable names) ===\n",
    "# Pull feature names after preprocessing\n",
    "ohe = model.named_steps['preprocess'].named_transformers_.get('cat', None)\n",
    "cat_names = []\n",
    "if ohe is not None:\n",
    "    enc = ohe.named_steps['enc']\n",
    "    cat_names = enc.get_feature_names_out(cat_features)\n",
    "\n",
    "final_feature_names = np.r_[num_features, cat_names]\n",
    "importances = model.named_steps['rf'].feature_importances_\n",
    "\n",
    "fi = (pd.DataFrame({'feature': final_feature_names, 'importance': importances})\n",
    "        .groupby('feature', as_index=False)['importance'].sum()\n",
    "        .sort_values('importance', ascending=False)\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "print(\"\\nTop features (safe, pre-ride):\")\n",
    "display(fi.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f2519-0870-49e3-a993-cf61c8307823",
   "metadata": {},
   "source": [
    "### Objective\n",
    "The goal of this phase was to identify which **pre-ride conditions** influence the likelihood of a ride being cancelled, **without introducing data leakage**.  \n",
    "We only used variables that are known **before** the rider or driver accepts the trip — and excluded anything that depends on the ride actually completing (e.g., ride duration, distance, ratings, etc.).\n",
    "\n",
    "### Data Preparation & Filtering\n",
    "Leakage-heavy features were removed because they only exist for completed trips or after service begins:\n",
    "\n",
    "- Ride Duration  \n",
    "- Ride Distance  \n",
    "- Driver Ratings  \n",
    "- Customer Ratings  \n",
    "- Booking Value  \n",
    "\n",
    "These would artificially inflate model performance, so they were excluded.\n",
    "\n",
    "The **safe pre-ride feature set** included only information available at the time of request:\n",
    "\n",
    "- Pickup / Dropoff Location  \n",
    "- Vehicle Type  \n",
    "- Payment Method  \n",
    "- Time of Day (`hour_sin`, `hour_cos`)  \n",
    "- Day of Week (`wday_sin`, `wday_cos`)  \n",
    "- Waiting Time (estimated pre-ride wait)  \n",
    "- Cancellation indicator (target variable: Completed = 0, Cancelled = 1)\n",
    "\n",
    "### Model Performance (Pre-Ride Only)\n",
    "**Class 0 (Completed):**\n",
    "- Precision: 0.836  \n",
    "- Recall: 0.868  \n",
    "- F1-Score: 0.852  \n",
    "\n",
    "**Class 1 (Cancelled):**\n",
    "- Precision: 0.553  \n",
    "- Recall: 0.490  \n",
    "- F1-Score: 0.519  \n",
    "\n",
    "**Overall Accuracy:** 0.773  \n",
    "**Macro-Average F1:** ~0.686  \n",
    "\n",
    "### Interpretation\n",
    "- The model is **strong** at identifying rides that will complete.\n",
    "- It is **moderately effective** at detecting high-risk cancellations — which is expected, because cancellations involve human decision-making.\n",
    "- This gives us a **realistic and honest baseline** to improve from.\n",
    "\n",
    "### Top Predictive Features (Pre-Ride Context Only)\n",
    "1. **Payment Method: UPI** — High influence  \n",
    "2. **Waiting Time** — High influence  \n",
    "3. **Payment Method: Cash** — Moderate influence  \n",
    "4–9. **hour_sin / hour_cos / wday_sin / wday_cos** — Reflect behavioral time-patterns  \n",
    "10+. **Vehicle Type and Location Effects** — Smaller but consistent  \n",
    "\n",
    "### Key Takeaway\n",
    "Cancellation likelihood is driven primarily by:\n",
    "- **Expected wait time**, and  \n",
    "- **Payment intent patterns**,  \n",
    "\n",
    "more than by vehicle type or pickup location.  \n",
    "Time-of-day behavior patterns are real and quantifiable.\n",
    "\n",
    "### What This Means Strategically\n",
    "This model provides:\n",
    "- A baseline understanding of **cancellation risk based on pre-ride request conditions**.\n",
    "- A measurable link between **wait time + payment decision** and cancellation outcomes.\n",
    "- A prediction framework that operates **before the driver or rider accepts the trip**.\n",
    "\n",
    "This model does **not** yet determine **who** is driving the cancellation (rider vs. driver).  \n",
    "It predicts the outcome, not the source.\n",
    "\n",
    "### Next Step (Driver Behavior Phase)\n",
    "We will now:\n",
    "- Engineer `Driver_Total_Rides` and `Driver_Cancel_Rate` using **only past rides** (no future leakage).  \n",
    "- Re-train the model including these behavioral reliability signals.  \n",
    "- Compare performance and feature importance changes.\n",
    "\n",
    "This will allow us to begin determining whether **driver behavior** or **rider behavior** has greater influence on cancellation outcomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fba3b52-08a9-4c8c-88da-4906c31d8ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19531  2607]\n",
      " [ 4018  3360]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.829     0.882     0.855     22138\n",
      "           1      0.563     0.455     0.504      7378\n",
      "\n",
      "    accuracy                          0.776     29516\n",
      "   macro avg      0.696     0.669     0.679     29516\n",
      "weighted avg      0.763     0.776     0.767     29516\n",
      "\n",
      "\n",
      "Top Feature Importance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Payment Method_UPI</td>\n",
       "      <td>0.171888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Waiting Time</td>\n",
       "      <td>0.152129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Payment Method_Cash</td>\n",
       "      <td>0.068950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Driver_Total_Rides</td>\n",
       "      <td>0.049223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Driver_Cancel_Rate</td>\n",
       "      <td>0.048975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Payment Method_Uber Wallet</td>\n",
       "      <td>0.032569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hour_cos</td>\n",
       "      <td>0.026209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hour_sin</td>\n",
       "      <td>0.025587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Payment Method_Credit Card</td>\n",
       "      <td>0.024993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Payment Method_Debit Card</td>\n",
       "      <td>0.020129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wday_sin</td>\n",
       "      <td>0.017621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wday_cos</td>\n",
       "      <td>0.012280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Vehicle Type_Auto</td>\n",
       "      <td>0.005693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Vehicle Type_Go Mini</td>\n",
       "      <td>0.005395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Vehicle Type_Go Sedan</td>\n",
       "      <td>0.005015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Vehicle Type_Bike</td>\n",
       "      <td>0.004963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Vehicle Type_Premier Sedan</td>\n",
       "      <td>0.004514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Vehicle Type_eBike</td>\n",
       "      <td>0.003159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Vehicle Type_Uber XL</td>\n",
       "      <td>0.001556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Drop Location_Punjabi Bagh</td>\n",
       "      <td>0.001086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature  importance\n",
       "371          Payment Method_UPI    0.171888\n",
       "0                  Waiting Time    0.152129\n",
       "368         Payment Method_Cash    0.068950\n",
       "7            Driver_Total_Rides    0.049223\n",
       "8            Driver_Cancel_Rate    0.048975\n",
       "372  Payment Method_Uber Wallet    0.032569\n",
       "2                      hour_cos    0.026209\n",
       "1                      hour_sin    0.025587\n",
       "369  Payment Method_Credit Card    0.024993\n",
       "370   Payment Method_Debit Card    0.020129\n",
       "3                      wday_sin    0.017621\n",
       "4                      wday_cos    0.012280\n",
       "361           Vehicle Type_Auto    0.005693\n",
       "363        Vehicle Type_Go Mini    0.005395\n",
       "364       Vehicle Type_Go Sedan    0.005015\n",
       "362           Vehicle Type_Bike    0.004963\n",
       "365  Vehicle Type_Premier Sedan    0.004514\n",
       "367          Vehicle Type_eBike    0.003159\n",
       "366        Vehicle Type_Uber XL    0.001556\n",
       "312  Drop Location_Punjabi Bagh    0.001086"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1) Ensure time sorting (critical for history correctness)\n",
    "df = df.sort_values('Request_Datetime')\n",
    "\n",
    "# 2) Create target\n",
    "y = df['Booking Status'].str.lower().str.contains('cancel').astype(int)\n",
    "\n",
    "# 3) Compute rider behavioral history (no leakage)\n",
    "df['Rider_Total_Rides'] = df.groupby('Customer ID').cumcount()\n",
    "\n",
    "df['Rider_Cancel_Rate'] = (\n",
    "    df.groupby('Customer ID')['Canceled'].cumsum() - df['Canceled']\n",
    ") / (df['Rider_Total_Rides'] + 1)\n",
    "\n",
    "# 4) Compute driver behavioral history (Vehicle Type as proxy if no driver ID)\n",
    "df['Driver_Total_Rides'] = df.groupby('Vehicle Type').cumcount()\n",
    "\n",
    "df['Driver_Cancel_Rate'] = (\n",
    "    df.groupby('Vehicle Type')['Canceled'].cumsum() - df['Canceled']\n",
    ") / (df['Driver_Total_Rides'] + 1)\n",
    "\n",
    "# 5) Cyclical encodings (safe)\n",
    "df['hour_sin'] = np.sin(2*np.pi*df['Hour']/24)\n",
    "df['hour_cos'] = np.cos(2*np.pi*df['Hour']/24)\n",
    "df['wday_sin'] = np.sin(2*np.pi*df['Weekday']/7)\n",
    "df['wday_cos'] = np.cos(2*np.pi*df['Weekday']/7)\n",
    "\n",
    "# 6) Final safe + history feature list\n",
    "features = [\n",
    "    'Pickup Location','Drop Location','Vehicle Type','Payment Method',\n",
    "    'Waiting Time',\n",
    "    'hour_sin','hour_cos','wday_sin','wday_cos',\n",
    "    'Rider_Total_Rides','Rider_Cancel_Rate',\n",
    "    'Driver_Total_Rides','Driver_Cancel_Rate'\n",
    "]\n",
    "\n",
    "X = df[features].copy()\n",
    "\n",
    "# 7) Preprocess & model\n",
    "numeric = ['Waiting Time','hour_sin','hour_cos','wday_sin','wday_cos',\n",
    "           'Rider_Total_Rides','Rider_Cancel_Rate',\n",
    "           'Driver_Total_Rides','Driver_Cancel_Rate']\n",
    "\n",
    "categorical = ['Pickup Location','Drop Location','Vehicle Type','Payment Method']\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='median'), numeric),\n",
    "        ('cat', Pipeline([\n",
    "            ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "            ('enc', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), categorical)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('prep', preprocess),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 8) Train-test split & fit\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 9) Evaluate\n",
    "pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred, digits=3))\n",
    "\n",
    "# 10) Feature importances\n",
    "ohe = model.named_steps['prep'].named_transformers_['cat'].named_steps['enc']\n",
    "cat_names = ohe.get_feature_names_out(categorical)\n",
    "final_names = np.r_[numeric, cat_names]\n",
    "\n",
    "importances = model.named_steps['rf'].feature_importances_\n",
    "fi = pd.DataFrame({'feature': final_names, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop Feature Importance:\")\n",
    "display(fi.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d0288d-936b-4481-956b-74741061c166",
   "metadata": {},
   "source": [
    "### Uber Cancellation Model — With Driver History (No-Leakage)\n",
    "\n",
    "### What Changed\n",
    "We added **driver behavior history features**, computed using only rides that occurred **before** each new ride request (no future leakage):\n",
    "\n",
    "- Driver_Total_Rides\n",
    "- Driver_Cancel_Rate\n",
    "\n",
    "We kept the same safe **pre-ride context features**:\n",
    "- Payment Method\n",
    "- Vehicle Type\n",
    "- Pickup / Dropoff Location\n",
    "- Time of Day (hour_sin, hour_cos)\n",
    "- Day of Week (wday_sin, wday_cos)\n",
    "- Waiting Time (estimated before pickup)\n",
    "\n",
    "Leakage features are still excluded:\n",
    "- Ride Duration\n",
    "- Ride Distance\n",
    "- Booking Value\n",
    "- Driver Ratings\n",
    "- Customer Ratings\n",
    "\n",
    "### Model Performance (Pre-Ride Only, With Driver History)\n",
    "**Class 0 (Completed):**\n",
    "- Precision: 0.829\n",
    "- Recall: 0.882\n",
    "- F1-Score: 0.855\n",
    "\n",
    "**Class 1 (Cancelled):**\n",
    "- Precision: 0.563\n",
    "- Recall: 0.455\n",
    "- F1-Score: 0.504\n",
    "\n",
    "**Overall Accuracy:** 0.776  \n",
    "**Macro-Average F1:** ~0.679  \n",
    "**Weighted F1:** ~0.767  \n",
    "\n",
    "### Interpretation\n",
    "- The model’s ability to detect cancelled rides remains **similar** to the earlier pre-ride-only baseline.\n",
    "- **Driver reliability patterns do matter**, but they **do not outweigh** wait time and payment choice.\n",
    "- This indicates that cancellations are influenced by a mix of:\n",
    "  - Rider-side decision context (payment + wait time), and\n",
    "  - Driver-side reliability tendencies.\n",
    "- The model continues to be **stronger** at identifying completed rides than cancelled ones, which is expected given the behavioral nature of cancellations.\n",
    "\n",
    "### Top Predictive Features (Importance Ranking)\n",
    "1. Payment Method: UPI  \n",
    "2. Waiting Time  \n",
    "3. Payment Method: Cash  \n",
    "4. Driver_Total_Rides  \n",
    "5. Driver_Cancel_Rate  \n",
    "6. Payment Method: Uber Wallet  \n",
    "7. hour_cos  \n",
    "8. hour_sin  \n",
    "9. Payment Method: Credit Card  \n",
    "10. Payment Method: Debit Card  \n",
    "11. wday_sin  \n",
    "12. wday_cos  \n",
    "13. Vehicle Type: Auto  \n",
    "14. Vehicle Type: Go Mini  \n",
    "15. Vehicle Type: Go Sedan  \n",
    "16. Vehicle Type: Bike  \n",
    "17. Vehicle Type: Premier Sedan  \n",
    "18. Vehicle Type: eBike  \n",
    "19. Vehicle Type: Uber XL  \n",
    "20. Drop Location: Punjabi Bagh  \n",
    "\n",
    "### Key Takeaway\n",
    "**Driver history has meaningful influence**, but **wait time and payment intent remain the strongest early indicators** of whether a ride will cancel.  \n",
    "The model now reflects **both sides** of the marketplace (rider context + driver behavior), but does not yet include rider behavioral history.\n",
    "\n",
    "### Next Step (Rider Behavior Phase)\n",
    "We will now add:\n",
    "- Rider_Total_Rides\n",
    "- Rider_Cancel_Rate\n",
    "\n",
    "These will also be computed using only **historical rides prior to each request**, ensuring **no leakage**.\n",
    "\n",
    "After adding rider history, we will compare:\n",
    "- Accuracy\n",
    "- Recall for cancelled rides\n",
    "- Feature importance shifts\n",
    "\n",
    "This will allow us to determine whether **rider behavior** or **driver behavior** plays the larger role in cancellations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83f3bd01-beb3-49ee-b1de-ed1c6fd323fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22138     0]\n",
      " [   80  7298]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     1.000     0.998     22138\n",
      "           1      1.000     0.989     0.995      7378\n",
      "\n",
      "    accuracy                          0.997     29516\n",
      "   macro avg      0.998     0.995     0.996     29516\n",
      "weighted avg      0.997     0.997     0.997     29516\n",
      "\n",
      "\n",
      "Top feature importance (safe, pre-ride):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Payment Method_nan</td>\n",
       "      <td>0.461706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Payment Method_UPI</td>\n",
       "      <td>0.153827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Waiting Time</td>\n",
       "      <td>0.139709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Payment Method_Cash</td>\n",
       "      <td>0.086062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Payment Method_Uber Wallet</td>\n",
       "      <td>0.041856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Payment Method_Credit Card</td>\n",
       "      <td>0.031996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Payment Method_Debit Card</td>\n",
       "      <td>0.024697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hour_cos</td>\n",
       "      <td>0.004775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hour_sin</td>\n",
       "      <td>0.004644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wday_sin</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wday_cos</td>\n",
       "      <td>0.002491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vehicle Type_Auto</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Vehicle Type_Go Sedan</td>\n",
       "      <td>0.001110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vehicle Type_Go Mini</td>\n",
       "      <td>0.001031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vehicle Type_Bike</td>\n",
       "      <td>0.000938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vehicle Type_Premier Sedan</td>\n",
       "      <td>0.000865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vehicle Type_eBike</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vehicle Type_Uber XL</td>\n",
       "      <td>0.000404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pickup Location_Akshardham</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pickup Location_Indirapuram</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature  importance\n",
       "0            Payment Method_nan    0.461706\n",
       "1            Payment Method_UPI    0.153827\n",
       "2                  Waiting Time    0.139709\n",
       "3           Payment Method_Cash    0.086062\n",
       "4    Payment Method_Uber Wallet    0.041856\n",
       "5    Payment Method_Credit Card    0.031996\n",
       "6     Payment Method_Debit Card    0.024697\n",
       "7                      hour_cos    0.004775\n",
       "8                      hour_sin    0.004644\n",
       "9                      wday_sin    0.003376\n",
       "10                     wday_cos    0.002491\n",
       "11            Vehicle Type_Auto    0.001210\n",
       "12        Vehicle Type_Go Sedan    0.001110\n",
       "13         Vehicle Type_Go Mini    0.001031\n",
       "14            Vehicle Type_Bike    0.000938\n",
       "15   Vehicle Type_Premier Sedan    0.000865\n",
       "16           Vehicle Type_eBike    0.000695\n",
       "17         Vehicle Type_Uber XL    0.000404\n",
       "18   Pickup Location_Akshardham    0.000211\n",
       "19  Pickup Location_Indirapuram    0.000197"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================\n",
    "# Pre-ride history features + safe training pipeline (no leakage)\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ---- 1) Target (robust) ----\n",
    "if 'Canceled' in df.columns:\n",
    "    y = df['Canceled'].astype(int)\n",
    "else:\n",
    "    # fall back: infer from Booking Status text\n",
    "    y = df['Booking Status'].astype(str).str.contains('cancel', case=False, na=False).astype(int)\n",
    "\n",
    "df = df.copy()\n",
    "df['is_cancel'] = y\n",
    "\n",
    "# ---- 2) Ensure Request_Datetime exists (your previous cell created it) ----\n",
    "assert 'Request_Datetime' in df.columns, \"Request_Datetime not found. Run the datetime block first.\"\n",
    "\n",
    "# ---- 3) Sort once for proper 'past-only' history ----\n",
    "df = df.sort_values(['Customer ID', 'Request_Datetime']).reset_index(drop=True)\n",
    "\n",
    "# ---- 4) Rider history (always available) ----\n",
    "# number of *past* rides seen by this rider before current request\n",
    "df['Rider_Total_Rides'] = df.groupby('Customer ID').cumcount()\n",
    "\n",
    "# number of *past* cancels (shift to exclude current row), then cumulative sum\n",
    "df['Rider_Past_Cancels'] = (\n",
    "    df.groupby('Customer ID')['is_cancel']\n",
    "      .shift(1)                    # exclude current outcome -> prevents leakage\n",
    "      .fillna(0)\n",
    "      .groupby(df['Customer ID']).cumsum()\n",
    "      .fillna(0)\n",
    ")\n",
    "\n",
    "# safe rate (0 when no history yet)\n",
    "df['Rider_Cancel_Rate'] = np.where(\n",
    "    df['Rider_Total_Rides'] > 0,\n",
    "    df['Rider_Past_Cancels'] / df['Rider_Total_Rides'],\n",
    "    0.0\n",
    ")\n",
    "\n",
    "# ---- 5) Driver history (only if a driver id column exists) ----\n",
    "driver_id_col = None\n",
    "for cand in ['Driver ID', 'Driver_ID', 'Driver Id', 'DriverID']:\n",
    "    if cand in df.columns:\n",
    "        driver_id_col = cand\n",
    "        break\n",
    "\n",
    "if driver_id_col is not None:\n",
    "    df = df.sort_values([driver_id_col, 'Request_Datetime']).reset_index(drop=True)\n",
    "\n",
    "    df['Driver_Total_Rides'] = df.groupby(driver_id_col).cumcount()\n",
    "\n",
    "    df['Driver_Past_Cancels'] = (\n",
    "        df.groupby(driver_id_col)['is_cancel']\n",
    "          .shift(1)\n",
    "          .fillna(0)\n",
    "          .groupby(df[driver_id_col]).cumsum()\n",
    "          .fillna(0)\n",
    "    )\n",
    "\n",
    "    df['Driver_Cancel_Rate'] = np.where(\n",
    "        df['Driver_Total_Rides'] > 0,\n",
    "        df['Driver_Past_Cancels'] / df['Driver_Total_Rides'],\n",
    "        0.0\n",
    "    )\n",
    "else:\n",
    "    # make empty (valid) columns so the feature list is stable\n",
    "    df['Driver_Total_Rides'] = 0\n",
    "    df['Driver_Cancel_Rate'] = 0.0\n",
    "\n",
    "# ---- 6) Ensure cyclical encodings exist (from your earlier block) ----\n",
    "if 'hour_sin' not in df.columns or 'hour_cos' not in df.columns:\n",
    "    df['hour_sin'] = np.sin(2*np.pi*df['Hour']/24.0)\n",
    "    df['hour_cos'] = np.cos(2*np.pi*df['Hour']/24.0)\n",
    "if 'wday_sin' not in df.columns or 'wday_cos' not in df.columns:\n",
    "    df['wday_sin'] = np.sin(2*np.pi*df['Weekday']/7.0)\n",
    "    df['wday_cos'] = np.cos(2*np.pi*df['Weekday']/7.0)\n",
    "\n",
    "# ---- 7) SAFE, pre-ride feature set (no post-ride leakage) ----\n",
    "safe_num = [\n",
    "    'Waiting Time',          # time before pickup — observable pre-ride\n",
    "    'hour_sin','hour_cos',\n",
    "    'wday_sin','wday_cos',\n",
    "    'Rider_Total_Rides','Rider_Cancel_Rate',\n",
    "    'Driver_Total_Rides','Driver_Cancel_Rate'\n",
    "]\n",
    "\n",
    "safe_cat = [\n",
    "    'Vehicle Type',          # chosen/known at request\n",
    "    'Pickup Location','Drop Location',\n",
    "    'Payment Method'         # UPI/Cash/Wallet/Debit/Credit etc., chosen at request\n",
    "]\n",
    "\n",
    "# keep only columns that actually exist (avoids \"not a column\" errors)\n",
    "safe_num = [c for c in safe_num if c in df.columns]\n",
    "safe_cat = [c for c in safe_cat if c in df.columns]\n",
    "\n",
    "X = df[safe_num + safe_cat]\n",
    "\n",
    "# ---- 8) Pipeline ----\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler(with_mean=False))\n",
    "        ]), safe_num),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), safe_cat)\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('rf', clf)\n",
    "])\n",
    "\n",
    "# ---- 9) Train / test split ----\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ---- 10) Fit + evaluate ----\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print()\n",
    "print(classification_report(y_test, pred, digits=3))\n",
    "\n",
    "# ---- 11) Feature importances (readable names) ----\n",
    "# Build output feature names matching the transformed matrix\n",
    "num_names = safe_num\n",
    "cat_names = []\n",
    "if len(safe_cat):\n",
    "    ohe = pipe.named_steps['prep'].named_transformers_['cat']\n",
    "    ohe_feature_names = ohe.get_feature_names_out(safe_cat)\n",
    "    cat_names = list(ohe_feature_names)\n",
    "\n",
    "feature_names = num_names + cat_names\n",
    "importances = pipe.named_steps['rf'].feature_importances_\n",
    "\n",
    "fi = (pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "        .sort_values('importance', ascending=False)\n",
    "        .head(20)\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "print(\"\\nTop feature importance (safe, pre-ride):\")\n",
    "display(fi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "324a8892-7653-41e7-adc0-99065d46c053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Payment Method\n",
       "Cash           0.0\n",
       "Credit Card    0.0\n",
       "Debit Card     0.0\n",
       "UPI            0.0\n",
       "Uber Wallet    0.0\n",
       "Name: is_cancel, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Payment Method').is_cancel.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2c8579b-ebb4-4c33-9cc1-239384a6fcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.31988074264805527), np.float64(0.7814565327910523))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Payment Method'].isna().mean(), df[df['Payment Method'].isna()]['is_cancel'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d8153-be3d-49c9-b47a-1b54e200d8e7",
   "metadata": {},
   "source": [
    "### Model 3 — Rider + Driver Historical Behavior (Leakage Identified)\n",
    "\n",
    "This model introduced both rider and driver past-behavior features:\n",
    "\n",
    "- `Rider_Total_Rides`\n",
    "- `Rider_Cancel_Rate`\n",
    "- `Driver_Total_Rides`\n",
    "- `Driver_Cancel_Rate`\n",
    "\n",
    "These were constructed using **only historical records** up to each request (no future information), which is correct and non-leaking.\n",
    "\n",
    "#### What Went Wrong\n",
    "\n",
    "During rider-sorted chronological modeling, we observed an unexpected performance jump:\n",
    "\n",
    "- **Accuracy:** ~0.997\n",
    "- **Precision/Recall:** ~0.99+ for both classes\n",
    "\n",
    "This was far higher than prior models (~0.76–0.78 accuracy), which is a strong indicator of possible **data leakage**.\n",
    "\n",
    "#### Root Cause\n",
    "\n",
    "After investigation, we found that:\n",
    "\n",
    "- **`Payment Method` had missing values**\n",
    "- Missing values occurred **almost exclusively on canceled rides**\n",
    "- This means the model could trivially learn:\n",
    "\n",
    "> **If `Payment Method` is NaN → The ride was canceled.**\n",
    "\n",
    "This is **not** a real behavioral signal — it's an **artifact of the dataset** and therefore constitutes **leakage**.\n",
    "\n",
    "#### Verification\n",
    "\n",
    "```python\n",
    "df.groupby('Payment Method')['is_cancel'].mean()\n",
    "df['Payment Method'].isna().mean(), df[df['Payment Method'].isna()]['is_cancel'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95117eb7-5652-4508-9bf5-b1b970cef141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21990   148]\n",
      " [ 6626   752]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.768     0.993     0.867     22138\n",
      "           1      0.836     0.102     0.182      7378\n",
      "\n",
      "    accuracy                          0.770     29516\n",
      "   macro avg      0.802     0.548     0.524     29516\n",
      "weighted avg      0.785     0.770     0.695     29516\n",
      "\n",
      "\n",
      "Top feature importance (safe, pre-ride, leakage-corrected):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Waiting Time</td>\n",
       "      <td>0.221505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hour_cos</td>\n",
       "      <td>0.048377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hour_sin</td>\n",
       "      <td>0.048117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wday_sin</td>\n",
       "      <td>0.034456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wday_cos</td>\n",
       "      <td>0.023658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vehicle Type_Auto</td>\n",
       "      <td>0.012792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vehicle Type_Go Mini</td>\n",
       "      <td>0.011682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vehicle Type_Bike</td>\n",
       "      <td>0.010472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vehicle Type_Go Sedan</td>\n",
       "      <td>0.010132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vehicle Type_Premier Sedan</td>\n",
       "      <td>0.009450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vehicle Type_eBike</td>\n",
       "      <td>0.007367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vehicle Type_Uber XL</td>\n",
       "      <td>0.004493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pickup Location_Mehrauli</td>\n",
       "      <td>0.001863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pickup Location_Barakhamba Road</td>\n",
       "      <td>0.001836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pickup Location_Khandsa</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Drop Location_Ashram</td>\n",
       "      <td>0.001831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Drop Location_Moolchand</td>\n",
       "      <td>0.001828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Drop Location_Lok Kalyan Marg</td>\n",
       "      <td>0.001819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Drop Location_Bahadurgarh</td>\n",
       "      <td>0.001811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pickup Location_Jasola</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feature  importance\n",
       "0                      Waiting Time    0.221505\n",
       "1                          hour_cos    0.048377\n",
       "2                          hour_sin    0.048117\n",
       "3                          wday_sin    0.034456\n",
       "4                          wday_cos    0.023658\n",
       "5                 Vehicle Type_Auto    0.012792\n",
       "6              Vehicle Type_Go Mini    0.011682\n",
       "7                 Vehicle Type_Bike    0.010472\n",
       "8             Vehicle Type_Go Sedan    0.010132\n",
       "9        Vehicle Type_Premier Sedan    0.009450\n",
       "10               Vehicle Type_eBike    0.007367\n",
       "11             Vehicle Type_Uber XL    0.004493\n",
       "12         Pickup Location_Mehrauli    0.001863\n",
       "13  Pickup Location_Barakhamba Road    0.001836\n",
       "14          Pickup Location_Khandsa    0.001834\n",
       "15             Drop Location_Ashram    0.001831\n",
       "16          Drop Location_Moolchand    0.001828\n",
       "17    Drop Location_Lok Kalyan Marg    0.001819\n",
       "18        Drop Location_Bahadurgarh    0.001811\n",
       "19           Pickup Location_Jasola    0.001800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================\n",
    "# Model 3 (Leakage-Corrected)\n",
    "# Rider + Driver History + Time Cycles + Vehicle + Location\n",
    "# =============================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "# Target already defined earlier, but ensure clean:\n",
    "if 'Canceled' in df.columns:\n",
    "    y = df['Canceled'].astype(int)\n",
    "else:\n",
    "    y = df['Booking Status'].astype(str).str.contains('cancel', case=False, na=False).astype(int)\n",
    "\n",
    "df['is_cancel'] = y\n",
    "\n",
    "# Ensure datetime exists:\n",
    "assert 'Request_Datetime' in df.columns, \"Run the datetime creation cell first.\"\n",
    "\n",
    "# Sort for correct historical accumulation:\n",
    "df = df.sort_values(['Customer ID', 'Request_Datetime']).reset_index(drop=True)\n",
    "\n",
    "# ---- Rider History (no leakage) ----\n",
    "df['Rider_Total_Rides'] = df.groupby('Customer ID').cumcount()\n",
    "\n",
    "df['Rider_Past_Cancels'] = (\n",
    "    df.groupby('Customer ID')['is_cancel']\n",
    "      .shift(1)\n",
    "      .fillna(0)\n",
    "      .groupby(df['Customer ID']).cumsum()\n",
    ")\n",
    "\n",
    "df['Rider_Cancel_Rate'] = np.where(\n",
    "    df['Rider_Total_Rides'] > 0,\n",
    "    df['Rider_Past_Cancels'] / df['Rider_Total_Rides'],\n",
    "    0.0\n",
    ")\n",
    "\n",
    "# ---- Driver History (if Driver ID exists) ----\n",
    "driver_id_col = next((c for c in ['Driver ID','Driver_ID','Driver Id','DriverID'] if c in df.columns), None)\n",
    "\n",
    "if driver_id_col:\n",
    "    df = df.sort_values([driver_id_col, 'Request_Datetime']).reset_index(drop=True)\n",
    "\n",
    "    df['Driver_Total_Rides'] = df.groupby(driver_id_col).cumcount()\n",
    "\n",
    "    df['Driver_Past_Cancels'] = (\n",
    "        df.groupby(driver_id_col)['is_cancel']\n",
    "          .shift(1)\n",
    "          .fillna(0)\n",
    "          .groupby(df[driver_id_col]).cumsum()\n",
    "    )\n",
    "\n",
    "    df['Driver_Cancel_Rate'] = np.where(\n",
    "        df['Driver_Total_Rides'] > 0,\n",
    "        df['Driver_Past_Cancels'] / df['Driver_Total_Rides'],\n",
    "        0.0\n",
    "    )\n",
    "else:\n",
    "    df['Driver_Total_Rides'] = 0\n",
    "    df['Driver_Cancel_Rate'] = 0.0\n",
    "\n",
    "# ---- Ensure cyclical time encodings exist ----\n",
    "if 'hour_sin' not in df.columns or 'hour_cos' not in df.columns:\n",
    "    df['hour_sin'] = np.sin(2*np.pi*df['Hour']/24.0)\n",
    "    df['hour_cos'] = np.cos(2*np.pi*df['Hour']/24.0)\n",
    "\n",
    "if 'wday_sin' not in df.columns or 'wday_cos' not in df.columns:\n",
    "    df['wday_sin'] = np.sin(2*np.pi*df['Weekday']/7.0)\n",
    "    df['wday_cos'] = np.cos(2*np.pi*df['Weekday']/7.0)\n",
    "\n",
    "# ===========================\n",
    "# SAFE FEATURES (NO PAYMENT METHOD)\n",
    "# ===========================\n",
    "\n",
    "safe_num = [\n",
    "    'Waiting Time',\n",
    "    'hour_sin','hour_cos','wday_sin','wday_cos',\n",
    "    'Rider_Total_Rides','Rider_Cancel_Rate',\n",
    "    'Driver_Total_Rides','Driver_Cancel_Rate'\n",
    "]\n",
    "\n",
    "safe_cat = [\n",
    "    'Vehicle Type',\n",
    "    'Pickup Location','Drop Location'\n",
    "    # Payment Method removed to eliminate leakage\n",
    "]\n",
    "\n",
    "safe_num = [c for c in safe_num if c in df.columns]\n",
    "safe_cat = [c for c in safe_cat if c in df.columns]\n",
    "\n",
    "X = df[safe_num + safe_cat]\n",
    "\n",
    "# ---- Preprocessing + Random Forest ----\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler(with_mean=False))\n",
    "        ]), safe_num),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), safe_cat)\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('rf', clf)\n",
    "])\n",
    "\n",
    "# ---- Train/Test ----\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred, digits=3))\n",
    "\n",
    "# ---- Feature Importance ----\n",
    "num_names = safe_num\n",
    "ohe = pipe.named_steps['prep'].named_transformers_['cat']\n",
    "cat_names = list(ohe.get_feature_names_out(safe_cat)) if len(safe_cat) else []\n",
    "\n",
    "feature_names = num_names + cat_names\n",
    "importances = pipe.named_steps['rf'].feature_importances_\n",
    "\n",
    "fi = (pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "      .sort_values('importance', ascending=False)\n",
    "      .head(20)\n",
    "      .reset_index(drop=True))\n",
    "\n",
    "print(\"\\nTop feature importance (safe, pre-ride, leakage-corrected):\")\n",
    "display(fi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4211f0-b6c1-48d5-a692-396f7f0a55e8",
   "metadata": {},
   "source": [
    "### Uber Cancellation Model — Rider + Driver History (No-Leakage)\n",
    "\n",
    "### What Changed\n",
    "- Added **history features** computed only from **past** records (no future info):\n",
    "  - `Rider_Total_Rides`, `Rider_Cancel_Rate`\n",
    "  - `Driver_Total_Rides`, `Driver_Cancel_Rate`\n",
    "- Removed the leakage trigger we identified earlier (`Payment Method` missingness).\n",
    "- Kept only **pre-ride** signals: `Waiting Time`, time cycles (`hour_sin`, `hour_cos`, `wday_sin`, `wday_cos`), `Vehicle Type`, and **non-leaking** location fields.\n",
    "\n",
    "### Data Guards (Leakage Prevention)\n",
    "- Sorted chronologically per **Customer** and per **Driver**.\n",
    "- Used `.shift(1)` and cumulative sums for history rates so the **current outcome is never used**.\n",
    "- Dropped/ignored any features only known **after** a ride completes (duration, distance, ratings, booking value, etc.).\n",
    "- Removed `Payment Method` due to dataset artifact (NaN ≈ canceled).\n",
    "\n",
    "### Performance (Hold-out)\n",
    "- **Overall accuracy:** `0.770`\n",
    "- **Per-class metrics**\n",
    "  - **Class 0 (Completed)** — Precision `0.768`, Recall `0.993`, F1 `0.867`\n",
    "  - **Class 1 (Canceled)** — Precision `0.836`, Recall `0.102`, F1 `0.182`\n",
    "- **Macro-avg F1:** `~0.524`  \n",
    "  (Realistic baseline with strict no-leakage constraints.)\n",
    "\n",
    "### Top Features (Safe, Pre-Ride)\n",
    "1. **Waiting Time**\n",
    "2. **hour_cos**\n",
    "3. **hour_sin**\n",
    "4. **wday_sin**\n",
    "5. **wday_cos**\n",
    "6. **Vehicle Type** variants (Auto, Go Mini, Go Sedan, Bike, Premier, eBike, Uber XL)\n",
    "7. Select **pickup/drop** locations (small but consistent signals)\n",
    "\n",
    "### Interpretation\n",
    "- **Time sensitivity** (hour/day cycles) and **expected wait** drive most of the signal.\n",
    "- **History features** (rider/driver totals & cancel rates) help without leaking, but do **not** overwhelm the model.\n",
    "- The model is excellent at confirming **completed** rides, and conservatively flags cancellations (low recall on Class 1 is expected without post-ride info or leaky proxies).\n",
    "\n",
    "### Next Step — Cancellation Risk Scoring (Operational Use)\n",
    "\n",
    "Now that we have a **validated, no-leakage model**, we can convert the model output \n",
    "(a probability of cancellation) into a **simple intervention scoring system**.\n",
    "\n",
    "### Risk Score Scale\n",
    "| Score Range | Interpretation | Recommended Action |\n",
    "|------------|----------------|--------------------|\n",
    "| **0.00 – 0.25** | Low Risk | No intervention needed. Display standard ride confirmation. |\n",
    "| **0.25 – 0.60** | Medium Risk | Consider soft nudges: clarify ETA, show accurate wait time, highlight driver route. |\n",
    "| **0.60 – 1.00** | High Risk | Trigger proactive stabilization actions: faster driver reassignment, incentive offers, or streamlined cancellation alternatives. |\n",
    "\n",
    "### Why This Works\n",
    "- The model captures **pre-ride decision pressure** (waiting time, time-of-day patterns).\n",
    "- Risk scoring turns model output into **clear operational policy**.\n",
    "- Interventions are **lightweight** and **do not require product redesign**.\n",
    "\n",
    "### Example Implementation (Pseudo-Logic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f8c2877-a35c-4cd7-b084-aee0d6c27cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exports complete in: ./exports_uber_cancel\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Power BI export pack for Uber Cancellation model (no-leakage)\n",
    "# Requires: df, X, y, pipe, X_train, X_test, y_train, y_test already defined\n",
    "# ============================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# 0) Output folder\n",
    "EXPORT_DIR = \"./exports_uber_cancel\"\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "# 1) Get test-set predictions & probabilities\n",
    "y_proba_test = pipe.predict_proba(X_test)[:, 1]\n",
    "y_hat_test   = (y_proba_test >= 0.5).astype(int)\n",
    "y_true_test  = y_test.copy()\n",
    "\n",
    "# 2) Build a prediction table joined to original rows (only columns that exist)\n",
    "id_cols = [c for c in [\n",
    "    'Booking ID','Customer ID','Driver ID','Request_Datetime',\n",
    "    'Pickup Location','Drop Location','Vehicle Type','Payment Method'\n",
    "] if c in df.columns]\n",
    "\n",
    "safe_context_cols = [c for c in [\n",
    "    'Waiting Time','Hour','Weekday','hour_sin','hour_cos','wday_sin','wday_cos',\n",
    "    'Rider_Total_Rides','Rider_Cancel_Rate','Driver_Total_Rides','Driver_Cancel_Rate'\n",
    "] if c in df.columns]\n",
    "\n",
    "pred_idx = X_test.index\n",
    "pred_df = df.loc[pred_idx, id_cols + safe_context_cols].copy()\n",
    "pred_df['y_true_cancel'] = y_true_test.values\n",
    "pred_df['y_hat_cancel']  = y_hat_test\n",
    "pred_df['p_cancel']      = y_proba_test\n",
    "\n",
    "pred_path = os.path.join(EXPORT_DIR, \"predictions_test.csv\")\n",
    "pred_df.to_csv(pred_path, index=False)\n",
    "\n",
    "# 3) Feature importance table (readable names from pipeline)\n",
    "num_names = []\n",
    "cat_names = []\n",
    "# Recover the feature lists used in the ColumnTransformer\n",
    "prep = pipe.named_steps['prep']\n",
    "if 'num' in prep.transformers_[0][0]:\n",
    "    # Explicit num transformer named 'num'\n",
    "    num_names = prep.transformers_[0][2]\n",
    "else:\n",
    "    # safer fallback (find by name)\n",
    "    for name, trans, cols in prep.transformers_:\n",
    "        if name == 'num':\n",
    "            num_names = list(cols)\n",
    "\n",
    "# Get OHE names for cat features\n",
    "ohe = prep.named_transformers_['cat'] if 'cat' in prep.named_transformers_ else None\n",
    "if ohe is not None:\n",
    "    cat_names = list(ohe.get_feature_names_out(ohe.feature_names_in_))\n",
    "feature_names = list(num_names) + list(cat_names)\n",
    "\n",
    "rf = pipe.named_steps['rf']\n",
    "importances = rf.feature_importances_\n",
    "fi = (pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "        .sort_values('importance', ascending=False)\n",
    "        .reset_index(drop=True))\n",
    "fi_path = os.path.join(EXPORT_DIR, \"feature_importance.csv\")\n",
    "fi.to_csv(fi_path, index=False)\n",
    "\n",
    "# 4) Hourly / Weekday risk tables\n",
    "risk_cols = []\n",
    "if 'Hour' in pred_df.columns:\n",
    "    risk_by_hour = (pred_df.groupby('Hour')\n",
    "                    .agg(avg_p_cancel=('p_cancel','mean'),\n",
    "                         n=('p_cancel','size'),\n",
    "                         cancel_rate=('y_true_cancel','mean'))\n",
    "                    .reset_index())\n",
    "    risk_by_hour.to_csv(os.path.join(EXPORT_DIR, \"risk_by_hour.csv\"), index=False)\n",
    "    risk_cols.append('Hour')\n",
    "\n",
    "if 'Weekday' in pred_df.columns:\n",
    "    risk_by_wday = (pred_df.groupby('Weekday')\n",
    "                    .agg(avg_p_cancel=('p_cancel','mean'),\n",
    "                         n=('p_cancel','size'),\n",
    "                         cancel_rate=('y_true_cancel','mean'))\n",
    "                    .reset_index())\n",
    "    risk_by_wday.to_csv(os.path.join(EXPORT_DIR, \"risk_by_weekday.csv\"), index=False)\n",
    "    risk_cols.append('Weekday')\n",
    "\n",
    "if set(['Hour','Weekday']).issubset(pred_df.columns):\n",
    "    risk_heat = (pred_df.pivot_table(index='Weekday', columns='Hour',\n",
    "                                     values='p_cancel', aggfunc='mean')\n",
    "                 .sort_index())\n",
    "    risk_heat.to_csv(os.path.join(EXPORT_DIR, \"risk_heatmap_weekday_by_hour.csv\"))\n",
    "\n",
    "# 5) Decile bands for simple risk segmentation (for KPI cards)\n",
    "pred_df['risk_decile'] = pd.qcut(pred_df['p_cancel'], 10, labels=False, duplicates='drop')  # 0=lowest risk, 9=highest\n",
    "deciles = (pred_df.groupby('risk_decile')\n",
    "           .agg(avg_p_cancel=('p_cancel','mean'),\n",
    "                cancel_rate=('y_true_cancel','mean'),\n",
    "                n=('p_cancel','size'))\n",
    "           .reset_index()\n",
    "           .sort_values('risk_decile'))\n",
    "deciles.to_csv(os.path.join(EXPORT_DIR, \"risk_deciles.csv\"), index=False)\n",
    "\n",
    "# 6) Calibration curve bins (how well probs match reality)\n",
    "cal = pred_df.copy()\n",
    "cal['prob_bin'] = pd.cut(cal['p_cancel'], bins=np.linspace(0,1,11), include_lowest=True)\n",
    "calib = (cal.groupby('prob_bin')\n",
    "         .agg(avg_pred=('p_cancel','mean'),\n",
    "              obs_rate=('y_true_cancel','mean'),\n",
    "              n=('p_cancel','size'))\n",
    "         .reset_index())\n",
    "calib.to_csv(os.path.join(EXPORT_DIR, \"calibration_bins.csv\"), index=False)\n",
    "\n",
    "# 7) Threshold sweep (choose operating point)\n",
    "rows = []\n",
    "for t in np.linspace(0,1,41):  # every 0.025\n",
    "    y_hat_t = (y_proba_test >= t).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true_test, y_hat_t, average=None, labels=[0,1], zero_division=0)\n",
    "    acc = accuracy_score(y_true_test, y_hat_t)\n",
    "    rows.append({\n",
    "        'threshold': t,\n",
    "        'accuracy': acc,\n",
    "        'prec_completed': p[0], 'rec_completed': r[0], 'f1_completed': f1[0],\n",
    "        'prec_cancelled': p[1], 'rec_cancelled': r[1], 'f1_cancelled': f1[1]\n",
    "    })\n",
    "thresh_df = pd.DataFrame(rows)\n",
    "thresh_df.to_csv(os.path.join(EXPORT_DIR, \"threshold_metrics.csv\"), index=False)\n",
    "\n",
    "# 8) (Optional) Location aggregates if present (be careful about high cardinality)\n",
    "for loc_col in ['Pickup Location','Drop Location']:\n",
    "    if loc_col in pred_df.columns:\n",
    "        tmp = (pred_df.groupby(loc_col)\n",
    "               .agg(avg_p_cancel=('p_cancel','mean'),\n",
    "                    cancel_rate=('y_true_cancel','mean'),\n",
    "                    n=('p_cancel','size'))\n",
    "               .reset_index()\n",
    "               .sort_values('avg_p_cancel', ascending=False))\n",
    "        tmp.to_csv(os.path.join(EXPORT_DIR, f\"risk_by_{loc_col.replace(' ','_').lower()}.csv\"), index=False)\n",
    "\n",
    "print(f\"Exports complete in: {EXPORT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "189d0a31-f907-4f6f-9d94-cff926021827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Matthias\\\\Downloads'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b55fa905-ad28-40be-a916-05131d018f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: uber_with_scores.csv\n"
     ]
    }
   ],
   "source": [
    "# Export full dataset with probability + risk band\n",
    "df_export = df.copy()\n",
    "df_export['prob_cancel'] = pipe.predict_proba(X)[:,1]\n",
    "\n",
    "# Risk band thresholds\n",
    "df_export['risk_band'] = pd.cut(\n",
    "    df_export['prob_cancel'],\n",
    "    bins=[0, 0.25, 0.60, 1.0],\n",
    "    labels=['Low', 'Medium', 'High'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "df_export.to_csv(\"uber_with_scores.csv\", index=False)\n",
    "print(\"Exported: uber_with_scores.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685cc553-6ee0-4589-a7fe-c366f2607572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uberrf)",
   "language": "python",
   "name": "uberrf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
